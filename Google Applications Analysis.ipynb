{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, sqlite3\n",
    "import numpy\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Google Play Store Dataset\", exist_ok=True)\n",
    "Dataset_Path = os.path.join(\"Google Play Store Dataset\", \"Google Play Store Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Store = pandas.read_csv(Dataset_Path)\n",
    "SQLite3_Dataset = Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLite3:\n",
    "    def __init__(self, Dataset , Name):\n",
    "        self.Dataset = Dataset\n",
    "        self.Name = Name\n",
    "        \n",
    "    def SQLite3_Connection(self):\n",
    "        if self.Name + \".db\" not in glob.glob(\"*db\"):\n",
    "            Connection = sqlite3.connect(self.Name + \".db\")\n",
    "            self.Dataset.to_sql(self.Name, Connection, if_exists='replace', index=False)\n",
    "            print(\"Database already created!\")\n",
    "            return Connection\n",
    "        else: return sqlite3.connect(self.Name + \".db\")\n",
    "\n",
    "    def Exc(self, Query):\n",
    "        Connection = self.SQLite3_Connection()\n",
    "        return pandas.read_sql_query(Query, Connection)\n",
    "    \n",
    "Conn = SQLite3(SQLite3_Dataset, 'Google Play Store Application')\n",
    "Query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM 'Google Play Store Application'\n",
    "\"\"\"        \n",
    "# Conn.Exc(Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Cleanning:\n",
    "    def __init__(self, Dataset):\n",
    "        self.Dataset = Dataset.copy().dropna()\n",
    "        self.Cleaned_Dataset = self.Data_cleaning()\n",
    "    \n",
    "    def Data_cleaning(self):\n",
    "        columns = ['Category', 'Reviews', 'Installs', 'Type', 'Content Rating', 'Genres']\n",
    "        for Column_Name in self.Dataset.columns:\n",
    "            if Column_Name in columns:\n",
    "                try:\n",
    "                    self.Dataset[Column_Name] = self.Dataset[Column_Name].astype(str) \n",
    "                    Column_Cleaning = {Values: Index for Index, Values in enumerate(self.Dataset[Column_Name].unique())}\n",
    "                    self.Dataset.loc[:, Column_Name] = self.Dataset[Column_Name].map(Column_Cleaning)                    \n",
    "                except ValueError:\n",
    "                    pass\n",
    "                \n",
    "        self.Dataset['Price'] = self.Dataset['Price'].apply(lambda x: 0 if x == 'Free' else float(x.strip('$')))         \n",
    "        self.Cleaned_Dataset = self.Dataset\n",
    "        return self.Cleaned_Dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "234/234 [==============================] - 8s 9ms/step - loss: 34.1085 - mae: 4.5904 - val_loss: 25.4191 - val_mae: 3.8594\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 2s 6ms/step - loss: 20.0549 - mae: 3.3895 - val_loss: 18.2654 - val_mae: 3.2586\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 2s 6ms/step - loss: 12.0360 - mae: 2.6327 - val_loss: 14.1492 - val_mae: 2.8098\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 7.0197 - mae: 1.9842 - val_loss: 13.9395 - val_mae: 2.7636\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 4.5172 - mae: 1.5733 - val_loss: 14.0774 - val_mae: 2.7712\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 3.4034 - mae: 1.3825 - val_loss: 14.0958 - val_mae: 2.7742\n",
      "Epoch 7/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 2.8562 - mae: 1.2575 - val_loss: 13.8350 - val_mae: 2.7357\n",
      "Epoch 8/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 2.3114 - mae: 1.1305 - val_loss: 13.4650 - val_mae: 2.6853\n",
      "Epoch 9/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 2.1056 - mae: 1.0804 - val_loss: 13.3750 - val_mae: 2.6704\n",
      "Epoch 10/20\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 1.8477 - mae: 1.0045 - val_loss: 13.1209 - val_mae: 2.6476\n",
      "Epoch 11/20\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 1.6900 - mae: 0.9600 - val_loss: 13.1427 - val_mae: 2.6391\n",
      "Epoch 12/20\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 1.5709 - mae: 0.9218 - val_loss: 13.0335 - val_mae: 2.6283\n",
      "Epoch 13/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.4880 - mae: 0.8990 - val_loss: 13.1755 - val_mae: 2.6372\n",
      "Epoch 14/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.3866 - mae: 0.8687 - val_loss: 13.1883 - val_mae: 2.6367\n",
      "Epoch 15/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.3493 - mae: 0.8539 - val_loss: 13.2846 - val_mae: 2.6522\n",
      "Epoch 16/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.3240 - mae: 0.8393 - val_loss: 13.5909 - val_mae: 2.6833\n",
      "Epoch 17/20\n",
      "234/234 [==============================] - 2s 6ms/step - loss: 1.2690 - mae: 0.8314 - val_loss: 13.9744 - val_mae: 2.7312\n",
      "Epoch 18/20\n",
      "234/234 [==============================] - 2s 6ms/step - loss: 1.1838 - mae: 0.8034 - val_loss: 13.7106 - val_mae: 2.6932\n",
      "Epoch 19/20\n",
      "234/234 [==============================] - 2s 6ms/step - loss: 1.1716 - mae: 0.7961 - val_loss: 13.5275 - val_mae: 2.6709\n",
      "Epoch 20/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.1526 - mae: 0.7892 - val_loss: 13.7303 - val_mae: 2.6983\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 13.7303 - mae: 2.6983\n",
      "MAE trên tập kiểm tra: 2.70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21c13e068c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class App_Trend_Model:\n",
    "    def __init__(self, Dataset):\n",
    "        cleaned_data = Dataset_Cleanning(Dataset).Cleaned_Dataset\n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = self.Data_Preparation(cleaned_data)\n",
    "        self.Model = self.Build_Model()\n",
    "\n",
    "    def Data_Preparation(self, Dataset):\n",
    "        X = Dataset.drop(['Category', 'Reviews', 'Type', 'Content Rating', 'Genres', 'Price'], axis=1)  # Các feature\n",
    "        Y = Dataset['Installs'].astype(float)\n",
    "        \n",
    "        # Xử lý dữ liệu phân loại (Category, Genres, Type, etc.)\n",
    "        X = pandas.get_dummies(X, drop_first=True)  \n",
    "\n",
    "        # Chuẩn hóa dữ liệu đầu vào\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        # Định hình lại dữ liệu cho LSTM (samples, timesteps, features)\n",
    "        X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "        # Chia tập train/test\n",
    "        return train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    def Build_Model(self):\n",
    "        # Xây dựng mô hình LSTM\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, input_shape=(1, self.X_train.shape[2]), return_sequences=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(LSTM(32))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def Train_Model(self, epochs=10, batch_size=32):\n",
    "        # Huấn luyện mô hình\n",
    "        history = self.Model.fit(\n",
    "            self.X_train, self.Y_train,\n",
    "            validation_data=(self.X_test, self.Y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Đánh giá mô hình\n",
    "        test_loss, test_mae = self.Model.evaluate(self.X_test, self.Y_test)\n",
    "        print(f\"MAE trên tập kiểm tra: {test_mae:.2f}\")\n",
    "        return history\n",
    "\n",
    "model = App_Trend_Model(Store)\n",
    "model.Train_Model(epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
