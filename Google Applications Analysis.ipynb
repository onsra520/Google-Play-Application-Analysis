{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, sqlite3\n",
    "import numpy\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Google Play Store Dataset\", exist_ok=True)\n",
    "Dataset_Path = os.path.join(\"Google Play Store Dataset\", \"Google Play Store Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Store = pandas.read_csv(Dataset_Path)\n",
    "SQLite3_Dataset = Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLite3:\n",
    "    def __init__(self, Dataset , Name):\n",
    "        self.Dataset = Dataset\n",
    "        self.Name = Name\n",
    "        \n",
    "    def SQLite3_Connection(self):\n",
    "        if self.Name + \".db\" not in glob.glob(\"*db\"):\n",
    "            Connection = sqlite3.connect(self.Name + \".db\")\n",
    "            self.Dataset.to_sql(self.Name, Connection, if_exists='replace', index=False)\n",
    "            print(\"Database already created!\")\n",
    "            return Connection\n",
    "        else: return sqlite3.connect(self.Name + \".db\")\n",
    "\n",
    "    def Exc(self, Query):\n",
    "        Connection = self.SQLite3_Connection()\n",
    "        return pandas.read_sql_query(Query, Connection)\n",
    "    \n",
    "Conn = SQLite3(SQLite3_Dataset, 'Google Play Store Application')\n",
    "Query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM 'Google Play Store Application'\n",
    "\"\"\"        \n",
    "# Conn.Exc(Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Cleanning:\n",
    "    def __init__(self, Dataset):\n",
    "        self.Dataset = Dataset.copy().dropna()\n",
    "        self.Cleaned_Dataset = self.Data_cleaning()\n",
    "    \n",
    "    def Data_cleaning(self):\n",
    "        columns = ['Category', 'Reviews', 'Installs', 'Type', 'Content Rating', 'Genres']\n",
    "        for Column_Name in self.Dataset.columns:\n",
    "            if Column_Name in columns:\n",
    "                try:\n",
    "                    self.Dataset[Column_Name] = self.Dataset[Column_Name].astype(str) \n",
    "                    Column_Cleaning = {Values: Index for Index, Values in enumerate(self.Dataset[Column_Name].unique())}\n",
    "                    self.Dataset.loc[:, Column_Name] = self.Dataset[Column_Name].map(Column_Cleaning)                    \n",
    "                except ValueError:\n",
    "                    pass\n",
    "                \n",
    "        self.Dataset['Price'] = self.Dataset['Price'].apply(lambda x: 0 if x == 'Free' else float(x.strip('$')))         \n",
    "        self.Cleaned_Dataset = self.Dataset\n",
    "        return self.Cleaned_Dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "234/234 [==============================] - 4s 8ms/step - loss: 33.9182 - mae: 4.5895 - val_loss: 25.8120 - val_mae: 3.9148\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 20.0882 - mae: 3.3935 - val_loss: 19.0302 - val_mae: 3.2975\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 12.2944 - mae: 2.6465 - val_loss: 13.9856 - val_mae: 2.7752\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 7.0564 - mae: 2.0024 - val_loss: 13.5528 - val_mae: 2.7021\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 1s 5ms/step - loss: 4.4766 - mae: 1.5814 - val_loss: 13.5960 - val_mae: 2.7033\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 3.4274 - mae: 1.3728 - val_loss: 13.1742 - val_mae: 2.6657\n",
      "Epoch 7/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 2.8586 - mae: 1.2610 - val_loss: 13.0375 - val_mae: 2.6414\n",
      "Epoch 8/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 2.3734 - mae: 1.1456 - val_loss: 12.8972 - val_mae: 2.6135\n",
      "Epoch 9/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 2.0685 - mae: 1.0662 - val_loss: 12.8561 - val_mae: 2.6132\n",
      "Epoch 10/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.8463 - mae: 1.0048 - val_loss: 12.8637 - val_mae: 2.6180\n",
      "Epoch 11/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.7074 - mae: 0.9626 - val_loss: 12.8157 - val_mae: 2.6130\n",
      "Epoch 12/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.5748 - mae: 0.9251 - val_loss: 12.7492 - val_mae: 2.6023\n",
      "Epoch 13/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.5057 - mae: 0.9043 - val_loss: 12.7946 - val_mae: 2.6054\n",
      "Epoch 14/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.3551 - mae: 0.8548 - val_loss: 12.8125 - val_mae: 2.6004\n",
      "Epoch 15/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.3649 - mae: 0.8558 - val_loss: 12.8199 - val_mae: 2.5971\n",
      "Epoch 16/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.2753 - mae: 0.8280 - val_loss: 12.9036 - val_mae: 2.6009\n",
      "Epoch 17/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.2040 - mae: 0.7968 - val_loss: 12.8157 - val_mae: 2.5852\n",
      "Epoch 18/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.1978 - mae: 0.7974 - val_loss: 12.6668 - val_mae: 2.5686\n",
      "Epoch 19/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.1271 - mae: 0.7776 - val_loss: 12.7369 - val_mae: 2.5709\n",
      "Epoch 20/20\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 1.0920 - mae: 0.7629 - val_loss: 12.8077 - val_mae: 2.5831\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 12.8077 - mae: 2.5831\n",
      "MAE trên tập kiểm tra: 2.58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200d916fdf0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class App_Trend_Model:\n",
    "    def __init__(self, Dataset):\n",
    "        cleaned_data = Dataset_Cleanning(Dataset).Cleaned_Dataset\n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = self.Data_Preparation(cleaned_data)\n",
    "        self.Model = self.Build_Model()\n",
    "\n",
    "    def Data_Preparation(self, Dataset):\n",
    "        X = Dataset.drop(['Category', 'Reviews', 'Type', 'Content Rating', 'Genres', 'Price'], axis=1)  # Các feature\n",
    "        Y = Dataset['Installs'].astype(float)\n",
    "        \n",
    "        # Xử lý dữ liệu phân loại (Category, Genres, Type, etc.)\n",
    "        X = pandas.get_dummies(X, drop_first=True)  \n",
    "\n",
    "        # Chuẩn hóa dữ liệu đầu vào\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        # Định hình lại dữ liệu cho LSTM (samples, timesteps, features)\n",
    "        X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "        # Chia tập train/test\n",
    "        return train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    def Build_Model(self):\n",
    "        # Xây dựng mô hình LSTM\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(64, input_shape=(1, self.X_train.shape[2]), return_sequences=True))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(LSTM(32))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def Train_Model(self, epochs=10, batch_size=32):\n",
    "        # Huấn luyện mô hình\n",
    "        history = self.Model.fit(\n",
    "            self.X_train, self.Y_train,\n",
    "            validation_data=(self.X_test, self.Y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # Đánh giá mô hình\n",
    "        test_loss, test_mae = self.Model.evaluate(self.X_test, self.Y_test)\n",
    "        print(f\"MAE trên tập kiểm tra: {test_mae:.2f}\")\n",
    "        return history\n",
    "\n",
    "model = App_Trend_Model(Store)\n",
    "model.Train_Model(epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
